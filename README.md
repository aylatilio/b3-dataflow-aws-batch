ğŸ”— RepositÃ³rio: [github.com/aylatilio/b3-dataflow-aws-batch](https://github.com/aylatilio/b3-dataflow-aws-batch.git)

# ğŸ¦ b3-dataflow-aws-batch
Pipeline de dados batch na AWS para ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise do Ã­ndice IBOVESPA, com automaÃ§Ã£o via S3, Lambda, Glue e Athena.

---

## ğŸ‘©â€ğŸ’» Autoria
**Ayla Atilio**  
ğŸ“š PÃ³s-graduaÃ§Ã£o em Machine Learning Engineering â€” FIAP  
ğŸ Python | â˜ï¸ AWS | ğŸ“Š Data Engineering  
ğŸ”— [linkedin.com/in/aylaatilio](https://linkedin.com/in/aylaatilio)  
ğŸ”— [github.com/aylatilio](https://github.com/aylatilio)

---

## ğŸ“˜ VisÃ£o Geral
Este projeto demonstra a implementaÃ§Ã£o de um **pipeline batch de engenharia de dados** na **AWS**, utilizando dados pÃºblicos da **B3 (Bolsa de Valores do Brasil)**.  

O fluxo realiza **ingestÃ£o, transformaÃ§Ã£o, catalogaÃ§Ã£o e anÃ¡lise** de dados histÃ³ricos do **Ã­ndice IBOVESPA**, com automaÃ§Ã£o baseada em eventos no S3 e consultas via Athena.  
Projeto desenvolvido como parte do **Tech Challenge 2 â€” FIAP (Machine Learning Engineering)**.

---

### ğŸš€ Objetivo
Demonstrar um pipeline de **dados escalÃ¡vel, modular e automatizado**, que conecta serviÃ§os da AWS em um fluxo **end-to-end**:

**S3 (armazenamento) â†’ Lambda (orquestraÃ§Ã£o) â†’ Glue (ETL) â†’ Athena (anÃ¡lise)**


---


## ğŸ§± Arquitetura

```mermaid
flowchart TD
    A["ğŸ“ˆ yfinance API (IBOV data)"] --> B(["ğŸª£ S3 Bucket raw/ parquet partitioned"])
    B -->|âš¡ S3 Event Trigger| C(["âš™ï¸ AWS Lambda"])
    C --> D(("ğŸ§© AWS Glue Job ETL Transformation"))
    D --> E(["ğŸ’¾ S3 Bucket refined/ parquet + partitions"])
    E --> F{{"ğŸ“š AWS Glue Crawler & Data Catalog"}}
    F --> G["ğŸ” Amazon Athena SQL Queries & Analytics"]
```

ğŸ“ˆ Fonte de dados: API Yahoo Finance (yfinance)  
ğŸ’¾ Armazenamento: AWS S3 (camadas raw e refined)  
âš™ï¸ OrquestraÃ§Ã£o: AWS Lambda + Glue Job ETL  
ğŸ“š CatÃ¡logo e Consulta: AWS Glue Catalog + Amazon Athena


---

## ğŸ—‚ï¸ Estrutura
```plaintext
b3-dataflow-aws-batch/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # dados brutos (Parquet)
â”‚   â””â”€â”€ refined/                  # dados transformados localmente
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract_ibov.py           # extraÃ§Ã£o e ingestÃ£o de dados do IBOV via yfinance
â”‚   â”œâ”€â”€ upload_s3.py              # upload automÃ¡tico para o S3 bucket raw/
â”‚   â”œâ”€â”€ lambda_trigger.py         # funÃ§Ã£o Lambda (dispara o Glue Job)
â”‚   â”œâ”€â”€ glue_job_etl.py           # ETL rodando no AWS Glue
â”‚   â””â”€â”€ glue_job_etl_local.py     # simulaÃ§Ã£o local do Glue Job
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ athena_queries.ipynb      # consultas e anÃ¡lises via Athena
â”‚   â””â”€â”€ ibov_ml_analysis.ipynb    # EDA e modelo preditivo (RegressÃ£o Linear)
â”‚
â”œâ”€â”€ docs/                         # documentaÃ§Ã£o e diagramas
â”‚   â””â”€â”€ diagrams/
â”‚       â”œâ”€â”€ architecture.mmd
â”‚       â””â”€â”€ architecture.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---


ğŸ”„ Pipeline de ExecuÃ§Ã£o â€” End-to-End Flow

| Etapa                         | Ambiente / ServiÃ§o       | DescriÃ§Ã£o                                                                                                 |
| ----------------------------- | ------------------------ | --------------------------------------------------------------------------------------------------------- |
| ğŸ **extract_ibov.py**        | Local (VS Code)          | Extrai dados do Ã­ndice IBOVESPA via `yfinance` e gera o arquivo parquet bruto (`data/raw/`).              |
| â˜ï¸ **upload_s3.py**           | Local â†’ Amazon S3 (raw)  | Faz o upload automÃ¡tico do parquet gerado para o bucket `b3-dataflow-raw/raw/`.                           |
| âš¡ **lambda_trigger.py**       | AWS Lambda               | Detecta novos arquivos no bucket *raw* e dispara automaticamente o Glue Job `b3-etl-job`.                 |
| ğŸ§© **glue_job_etl.py**        | AWS Glue                 | Executa o ETL: transforma, renomeia colunas, calcula mÃ©dias mÃ³veis e grava o dataset refinado.            |
| ğŸ§© **glue_job_etl_local.py**  | Local (VS Code)          | Simula o Glue Job localmente, gerando o parquet `ibov_refined.parquet` em `data/refined/`.                |
| ğŸ’¾ **Buckets Raw / Refined**  | Amazon S3                | Armazenam as camadas de dados (raw = bruta / refined = transformada) em formato Parquet particionado.     |
| ğŸ“š **Glue Catalog / Crawler** | AWS Glue Data Catalog    | Atualiza o schema e registra a tabela `ibov_refined`, permitindo consulta via Athena.                     |
| ğŸ” **athena_queries.ipynb**   | Local â†’ Amazon Athena    | Executa queries SQL sobre os dados refinados via `boto3` e `awswrangler`.                                 |
| ğŸ¤– **ibov_ml_analysis.ipynb** | Local (Jupyter Notebook) | Realiza EDA e treina modelo de **RegressÃ£o Linear** com `scikit-learn` para prever o preÃ§o de fechamento. |

ğŸ’¡ Essa visÃ£o unificada mostra a integraÃ§Ã£o Local â†” AWS, cobrindo todas as etapas do pipeline:

# ExtraÃ§Ã£o â†’ Upload â†’ OrquestraÃ§Ã£o â†’ ETL â†’ CatÃ¡logo â†’ AnÃ¡lise â†’ Machine Learning


---


âš™ï¸ Requisitos e ExecuÃ§Ã£o do Pipeline

ğŸ§© PrÃ©-requisitos

	Python 3.11.9

Conta AWS com permissÃµes em: S3, Glue, Lambda, Athena, CloudWatch


Credenciais AWS configuradas localmente:

aws configure


Ambiente virtual Python ativo (venv):

python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt


ğŸš€ Etapas de ExecuÃ§Ã£o

1ï¸âƒ£ IngestÃ£o e Upload

python src/extract_ibov.py
python src/upload_s3.py

Extrai e envia dados brutos para b3-dataflow-raw/raw/.


2ï¸âƒ£ OrquestraÃ§Ã£o via Lambda

A funÃ§Ã£o lambda_trigger.py dispara o Glue Job (b3-etl-job) sempre que um novo arquivo .parquet Ã© adicionado ao bucket raw.

Evento: ObjectCreated:Put
Resultado: parquet refinado em b3-dataflow-refined/refined/.


3ï¸âƒ£ ETL (Glue / Local)

python src/glue_job_etl_local.py

Realiza transformaÃ§Ãµes, mÃ©dias mÃ³veis e salva data/refined/ibov_refined.parquet.


4ï¸âƒ£ CatÃ¡logo e Consulta (Athena)

jupyter notebook notebooks/athena_queries.ipynb

Executa queries SQL sobre o dataset ibov_refined registrado no Glue Catalog.
Gera estatÃ­sticas, volatilidade e amplitude.


5ï¸âƒ£ Machine Learning

jupyter notebook notebooks/ibov_ml_analysis.ipynb

LÃª o parquet refinado e executa:
EDA (estatÃ­sticas, visualizaÃ§Ã£o temporal)
RegressÃ£o Linear (sklearn)
Exibe grÃ¡fico de ajuste e mÃ©trica RÂ²

ğŸ’¡ Dica: O Glue Job pode ser executado manualmente no console antes de ativar o trigger Lambda, facilitando o debug inicial.

---


ğŸ” Consulta SQL no Amazon Athena

ApÃ³s o crawler atualizar o catÃ¡logo (b3_refined_db.ibov_refined), as consultas podem ser executadas diretamente no Athena.

```sql
SELECT
    data,
    preco_abertura,
    preco_fechamento,
    (preco_fechamento - preco_abertura) AS variacao_diaria,
    ROUND(((preco_fechamento - preco_abertura) / preco_abertura) * 100, 2) AS variacao_pct,
    volume_negociado
FROM "b3_refined_db"."ibov_refined"
WHERE year = 2025 AND month = 10
ORDER BY data DESC
LIMIT 10;
```

ğŸ“Š Resultado esperado (amostra):
| data       | preco_abertura | preco_fechamento | variacao_diaria | variacao_pct | volume_negociado |
| ---------- | -------------- | ---------------- | --------------- | ------------ | ---------------- |
| 2025-10-13 | 127.845,00     | 128.430,00       | 585,00          | 0.46 %       | 13 245 200       |
| 2025-10-10 | 128.290,00     | 127.845,00       | âˆ’445,00         | âˆ’0.35 %      | 12 988 500       |
| â€¦          | â€¦              | â€¦                | â€¦               | â€¦            | â€¦                |


ğŸ’¡ Dataset refinado disponÃ­vel no Athena, com cÃ¡lculos derivados e partiÃ§Ãµes atualizadas automaticamente via Glue Crawler.


---


ğŸ§  Machine Learning (AnÃ¡lise Preditiva)

Notebook: notebooks/ibov_ml_analysis.ipynb
Leitura do dataset ibov_refined.parquet
EstatÃ­sticas descritivas e grÃ¡fico temporal
Modelo LinearRegression (sklearn)
VariÃ¡vel alvo: preco_fechamento
VariÃ¡vel explicativa: media_movel_3d
MÃ©trica de avaliaÃ§Ã£o: RÂ²

ğŸ’¡ ML aplicado, validando a utilidade analÃ­tica do dataset refinado.


---


## ğŸ§  ConclusÃ£o

O pipeline demonstra a integraÃ§Ã£o completa de serviÃ§os AWS para ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise de dados financeiros.
A arquitetura implementa boas prÃ¡ticas de Data Lake (raw/refined), ETL automatizado via Glue e anÃ¡lise via Athena, garantindo escalabilidade e rastreabilidade.
As features geradas (volatilidade, amplitude, mÃ©dias mÃ³veis) servem de base para aplicaÃ§Ãµes de Machine Learning, como detecÃ§Ã£o de anomalias e previsÃ£o de tendÃªncias.


---


## ğŸ”— ReferÃªncias
- [Yahoo Finance API (yfinance)](https://pypi.org/project/yfinance/)
- [AWS Glue Documentation](https://docs.aws.amazon.com/glue/index.html)
- [Amazon Athena Documentation](https://docs.aws.amazon.com/athena/)
- [Mermaid Live Editor](https://mermaid.live)
